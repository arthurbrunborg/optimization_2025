{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39fa2c30",
   "metadata": {},
   "source": [
    "# First Wolfe conditions\n",
    "\n",
    "## Introduction to optimization and operations research.\n",
    "\n",
    "Michel Bierlaire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f59cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import fsolve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7da081",
   "metadata": {},
   "source": [
    "In this lab, you will revisit **Newton’s method** on a simple quadratic objective and use it to\n",
    "practice the **first Wolfe condition** in an inexact line search. You will (i) compute the gradient\n",
    "and Hessian, (ii) form the **Newton direction** and verify it is a **descent direction** via the\n",
    "directional derivative, (iii) evaluate the objective along the line x(α) = x₀ + α d, and (iv) check\n",
    "for which step sizes α the **Wolfe decrease** holds. The goal is to connect the algebra\n",
    "(∇f, ∇²f, inner products) with practical line-search diagnostics and plots, so you see why Wolfe’s\n",
    "condition guards sufficient decrease while allowing reasonably large steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f231aead",
   "metadata": {},
   "source": [
    "Consider the unconstrained optimization problem\n",
    "$$\\min_{x \\in \\mathbb{R}^2} f(x)=4x_1^2-4x_1+x_2^2+2x_2,\n",
    "$$\n",
    "and the point $x_0=(0,0)^T$.\n",
    "\n",
    "- Calculate Newton's direction at $x_0$.\n",
    "- Verify that it is a descent direction.\n",
    "- Consider the first Wolfe condition with $\\beta_1=0.1$. What are\n",
    "the values of the step $\\alpha$ that verify the condition?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992564a8",
   "metadata": {},
   "source": [
    "First, implement the function and its derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9085b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def f(x: np.array) -> float:\n",
    "    \"\"\"Objective function\"\"\"\n",
    "    # Python starts the numbering at zero\n",
    "    x_1 = x[0]\n",
    "    x_2 = x[1]\n",
    "    result = 4 * x_1 * x_1 - 4 * x_1 + x_2 * x_2 + 2 * x_2\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3655ff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_zero = np.array([0.0, 0.0])\n",
    "f_zero = f(x_zero)\n",
    "print(f'f({x_zero}) = {f_zero}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dabbf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x: np.array) -> np.array:\n",
    "    \"\"\"Gradient of the objective function\"\"\"\n",
    "    x_1 = x[0]\n",
    "    x_2 = x[1]\n",
    "    g_1 = 8 * x_1 - 4\n",
    "    g_2 = 2 * x_2 + 2\n",
    "    return np.array([g_1, g_2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6d618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_zero = gradient(x_zero)\n",
    "print(f'Gradient of f({x_zero}) = {g_zero}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291f71ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian(x: np.array) -> np.array:\n",
    "    \"\"\"Second derivative matrix of the objective function\"\"\"\n",
    "    # In this case, the hessian does not depend on x\n",
    "    x_1 = x[0]\n",
    "    x_2 = x[1]\n",
    "    h_1_1 = 8\n",
    "    h_1_2 = 0\n",
    "    h_2_1 = 0\n",
    "    h_2_2 = 2\n",
    "    h = np.array([[h_1_1, h_1_2], [h_2_1, h_2_2]])\n",
    "    return h\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e181a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_zero = hessian(x_zero)\n",
    "print(f'Hessian of f({x_zero}) =\\n{h_zero}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b931e382",
   "metadata": {},
   "source": [
    "Note that there exists Python packages for automatic differentiation,\n",
    "such as ``autograd``or ``jax``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdafd97",
   "metadata": {},
   "source": [
    "Calculate Newton's direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0196125",
   "metadata": {},
   "outputs": [],
   "source": [
    "newton_direction = np.linalg.solve(h_zero, -g_zero)\n",
    "print(f\"Newton's direction: {newton_direction}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266ed083",
   "metadata": {},
   "source": [
    "Verify that it is a descent direction.\n",
    "We calculate the directional derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb11bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_derivative = np.inner(newton_direction, g_zero)\n",
    "print(f'Directional derivative: {directional_derivative}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da51518",
   "metadata": {},
   "source": [
    "It must be negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc6225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if directional_derivative < 0:\n",
    "    print('Descent direction')\n",
    "else:\n",
    "    print('Not a descent direction')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4d806e",
   "metadata": {},
   "source": [
    "Write the function that associates a step alpha along Newton's direction with the value of\n",
    "the objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de3a063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linesearch(alpha: float) -> float:\n",
    "    \"\"\"\n",
    "\n",
    "    :param alpha: step along the direction\n",
    "    :return: value of the objective function\n",
    "    \"\"\"\n",
    "    new_point = x_zero + alpha * newton_direction\n",
    "    return f(new_point)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc652e77",
   "metadata": {},
   "source": [
    "We plot the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95556497",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_values = np.linspace(0, 2.5, 100)\n",
    "objective_values = [linesearch(alpha) for alpha in alpha_values]\n",
    "plt.plot(alpha_values, objective_values)\n",
    "plt.xlabel('Step alpha')\n",
    "plt.ylabel('Objective Function Value')\n",
    "plt.title('Line Search Plot')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb3da96",
   "metadata": {},
   "source": [
    "Consider the first Wolfe condition with $\\beta_1=0.1$.\n",
    "$$\n",
    "f(x_\\alpha)  \\leq f(x_0) + \\alpha \\beta_1\\nabla f(x_0)^Td_N.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446df211",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1 = 0.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d578a0",
   "metadata": {},
   "source": [
    "Equation of the line defining the first Wolfe condition:\n",
    "$$\n",
    "y(\\alpha) = f(x_0) + \\alpha \\beta_1\\nabla f(x_0)^Td_N.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c71937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wolfe(alpha: float) -> float:\n",
    "    \"\"\"\n",
    "    First wolfe condition\n",
    "\n",
    "    :param alpha: step along the direction\n",
    "    :return: Wolfe condition\n",
    "    \"\"\"\n",
    "    result = f_zero + alpha * beta_1 * directional_derivative\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb1e498",
   "metadata": {},
   "source": [
    "Plot the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03735231",
   "metadata": {},
   "outputs": [],
   "source": [
    "wolfe_values = [wolfe(alpha) for alpha in alpha_values]\n",
    "plt.plot(alpha_values, objective_values)\n",
    "plt.plot(alpha_values, wolfe_values)\n",
    "plt.xlabel('Step alpha')\n",
    "plt.ylabel('Objective Function Value')\n",
    "plt.title('Line Search Plot')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c15fbc",
   "metadata": {},
   "source": [
    "What are the values of the step $\\alpha$ that verify the condition?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49adc941",
   "metadata": {},
   "source": [
    "We need to find the values of alpha such that the difference is positive:\n",
    "$$\n",
    "\\text{diff}(\\alpha) = f(x_0) + \\alpha \\beta_1\\nabla f(x_0)^Td_N - f(x_\\alpha) \\geq 0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b7266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference(alpha: float) -> float:\n",
    "    \"\"\"\n",
    "    Difference between the first wolfe condition and the function\n",
    "\n",
    "    :param alpha: step along the direction\n",
    "    :return: Wolfe condition\n",
    "    \"\"\"\n",
    "    return wolfe(alpha) - linesearch(alpha)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaeb896",
   "metadata": {},
   "source": [
    "Find the root of that function. Use the function `fsolve` from `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c5d09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = 1.5\n",
    "root = fsolve(difference, guess)[0]\n",
    "print(f'Intersection of the function and the Wolfe line: {root:.2g}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d002e7b6",
   "metadata": {},
   "source": [
    "Plot the function with the root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd46ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alpha_values, objective_values)\n",
    "plt.plot(alpha_values, wolfe_values)\n",
    "plt.axvline(root, color='red', linestyle='--')\n",
    "plt.xlabel('Step alpha')\n",
    "plt.ylabel('Objective Function Value')\n",
    "plt.title('Line Search Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aea517",
   "metadata": {},
   "source": [
    "The values of the step $\\alpha$ that verify the condition are\n",
    "$$ 0 < \\alpha \\leq 1.8$$."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
